{
  "model_name": "exp7_attention_mlp",
  "config": {
    "d_model": 768,
    "n_heads": 12,
    "n_layers": 8,
    "d_ff": 3072,
    "batch_size": 32,
    "max_steps": 2000,
    "gradient_accumulation_steps": 4,
    "muon_lr": 0.01,
    "max_seq_len": 256,
    "num_documents": 1000,
    "max_tokens": 100000,
    "eval_every": 200,
    "eval_steps": 50,
    "weight_decay": 0.01,
    "dropout": 0.1,
    "grad_clip": 1.0,
    "use_amp": false,
    "vocab_size": 49152,
    "log_milestones": [
      2000,
      5000,
      10000
    ],
    "num_experts": 8,
    "expert_top_k": 2,
    "load_balancing_weight": 0.01,
    "d_k": 64
  },
  "training_history": [
    {
      "step": 200,
      "train_loss": 0.03916188329458237,
      "val_loss": 1.3119722855091096,
      "val_accuracy": 0.88026611328125,
      "val_perplexity": 3.713490557999673,
      "learning_rate": 0.0009777564731873593
    },
    {
      "step": 400,
      "train_loss": 0.02349858172237873,
      "val_loss": 1.2340959978103638,
      "val_accuracy": 0.8842529296875,
      "val_perplexity": 3.4352716235261203,
      "learning_rate": 0.0009136417175896859
    },
    {
      "step": 600,
      "train_loss": 0.021590134128928185,
      "val_loss": 1.207895667552948,
      "val_accuracy": 0.8845849609375,
      "val_perplexity": 3.346435225754107,
      "learning_rate": 0.000813931177033507
    },
    {
      "step": 800,
      "train_loss": 0.02354614809155464,
      "val_loss": 1.1980288112163544,
      "val_accuracy": 0.88453369140625,
      "val_perplexity": 3.313578791560516,
      "learning_rate": 0.0006883852139526465
    },
    {
      "step": 1000,
      "train_loss": 0.017863702028989792,
      "val_loss": 1.1791542708873748,
      "val_accuracy": 0.885400390625,
      "val_perplexity": 3.2516230474130325,
      "learning_rate": 0.00054929314194362
    },
    {
      "step": 1200,
      "train_loss": 0.016920071095228195,
      "val_loss": 1.1882681089639664,
      "val_accuracy": 0.88572265625,
      "val_perplexity": 3.281393267772872,
      "learning_rate": 0.0004102702621261221
    },
    {
      "step": 1400,
      "train_loss": 0.019843101501464844,
      "val_loss": 1.1862663662433623,
      "val_accuracy": 0.88269287109375,
      "val_perplexity": 3.274831332529846,
      "learning_rate": 0.00028492510260604747
    },
    {
      "step": 1600,
      "train_loss": 0.017524663358926773,
      "val_loss": 1.162194641828537,
      "val_accuracy": 0.8819921875,
      "val_perplexity": 3.1969417248185406,
      "learning_rate": 0.00018552732092830138
    },
    {
      "step": 1800,
      "train_loss": 0.016724778339266777,
      "val_loss": 1.1539458227157593,
      "val_accuracy": 0.88471435546875,
      "val_perplexity": 3.1706791971514714,
      "learning_rate": 0.00012180666450856855
    }
  ],
  "final_metrics": {
    "val_loss": 1.1586869418621064,
    "val_accuracy": 0.88211181640625,
    "val_perplexity": 3.185747456981987
  },
  "training_time_minutes": 6.9181778947512305,
  "parameter_count": 102653184,
  "test_mode": false,
  "max_steps": 2000,
  "parameters_millions": 102.653184
}