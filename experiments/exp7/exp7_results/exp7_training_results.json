{
  "model_name": "exp7_attention_mlp",
  "config": {
    "d_model": 768,
    "n_heads": 12,
    "n_layers": 8,
    "d_ff": 3072,
    "batch_size": 32,
    "max_steps": 2000,
    "gradient_accumulation_steps": 4,
    "muon_lr": 0.01,
    "max_seq_len": 256,
    "num_documents": 1000,
    "max_tokens": 100000,
    "eval_every": 200,
    "eval_steps": 50,
    "weight_decay": 0.01,
    "dropout": 0.1,
    "grad_clip": 1.0,
    "use_amp": false,
    "vocab_size": 49152,
    "log_milestones": [
      2000,
      5000,
      10000
    ],
    "num_experts": 8,
    "expert_top_k": 2,
    "load_balancing_weight": 0.01,
    "d_k": 64
  },
  "training_history": [
    {
      "step": 200,
      "train_loss": 0.0349900908768177,
      "val_loss": 0.028499296605587005,
      "val_accuracy": 0.99657470703125,
      "val_perplexity": 1.0289092871052254,
      "learning_rate": 0.0009777564731873593
    },
    {
      "step": 400,
      "train_loss": 0.02463306486606598,
      "val_loss": 0.021682880520820617,
      "val_accuracy": 0.996796875,
      "val_perplexity": 1.021919662449332,
      "learning_rate": 0.0009136417175896859
    },
    {
      "step": 600,
      "train_loss": 0.022677943110466003,
      "val_loss": 0.020763696916401387,
      "val_accuracy": 0.99678955078125,
      "val_perplexity": 1.0209807622275264,
      "learning_rate": 0.000813931177033507
    },
    {
      "step": 800,
      "train_loss": 0.02181190438568592,
      "val_loss": 0.020255228541791438,
      "val_accuracy": 0.99676025390625,
      "val_perplexity": 1.0204617577587098,
      "learning_rate": 0.0006883852139526465
    },
    {
      "step": 1000,
      "train_loss": 0.020682010799646378,
      "val_loss": 0.019587468579411505,
      "val_accuracy": 0.99691162109375,
      "val_perplexity": 1.0197805617167728,
      "learning_rate": 0.00054929314194362
    },
    {
      "step": 1200,
      "train_loss": 0.021329043433070183,
      "val_loss": 0.019196545891463756,
      "val_accuracy": 0.9968603515625,
      "val_perplexity": 1.019381984270029,
      "learning_rate": 0.0004102702621261221
    },
    {
      "step": 1400,
      "train_loss": 0.02089041844010353,
      "val_loss": 0.01898134548217058,
      "val_accuracy": 0.99686279296875,
      "val_perplexity": 1.0191626364525044,
      "learning_rate": 0.00028492510260604747
    },
    {
      "step": 1600,
      "train_loss": 0.022031808272004128,
      "val_loss": 0.01826277207583189,
      "val_accuracy": 0.996923828125,
      "val_perplexity": 1.018430556343365,
      "learning_rate": 0.00018552732092830138
    },
    {
      "step": 1800,
      "train_loss": 0.015706824138760567,
      "val_loss": 0.017995141465216875,
      "val_accuracy": 0.9969873046875,
      "val_perplexity": 1.018158029621575,
      "learning_rate": 0.00012180666450856855
    }
  ],
  "final_metrics": {
    "val_loss": 0.017771621700376272,
    "val_accuracy": 0.99696533203125,
    "val_perplexity": 1.0179304766104686
  },
  "training_time_minutes": 6.914504166444143,
  "parameter_count": 102653184,
  "test_mode": false,
  "max_steps": 2000,
  "parameters_millions": 102.653184
}