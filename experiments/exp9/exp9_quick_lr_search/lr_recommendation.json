{
  "best_learning_rate": 0.003,
  "best_result": {
    "val_loss": 2.3904561519622805,
    "val_accuracy": 0.451605224609375,
    "val_perplexity": 10.9184732903026,
    "learning_rate": 0.003,
    "model_name": "attention_mlp_512d_lr_3.00e-03",
    "training_time_minutes": 2.223625457286835,
    "parameter_count": 69625088,
    "parameters_millions": 69.625088,
    "total_steps": 300,
    "best_val_loss": 2.7914459705352783,
    "best_step": 270,
    "early_stopped": false,
    "final_train_loss": 2.934880256652832,
    "final_lr": 0.0029339262969984574
  },
  "all_results": {
    "lr_1.00e-04": {
      "val_loss": 8.14340934753418,
      "val_accuracy": 0.03359375,
      "val_perplexity": 3440.6281916048274,
      "learning_rate": 0.0001,
      "model_name": "attention_mlp_512d_lr_1.00e-04",
      "training_time_minutes": 2.240921473503113,
      "parameter_count": 69625088,
      "parameters_millions": 69.625088,
      "total_steps": 300,
      "best_val_loss": 8.48330307006836,
      "best_step": 270,
      "early_stopped": false,
      "final_train_loss": 8.602276802062988,
      "final_lr": 9.779754323328192e-05
    },
    "lr_3.00e-04": {
      "val_loss": 6.444238376617432,
      "val_accuracy": 0.1248291015625,
      "val_perplexity": 629.0673820367022,
      "learning_rate": 0.0003,
      "model_name": "attention_mlp_512d_lr_3.00e-04",
      "training_time_minutes": 2.21868234872818,
      "parameter_count": 69625088,
      "parameters_millions": 69.625088,
      "total_steps": 300,
      "best_val_loss": 6.756759357452393,
      "best_step": 270,
      "early_stopped": false,
      "final_train_loss": 6.826024055480957,
      "final_lr": 0.0002933926296998457
    },
    "lr_1.00e-03": {
      "val_loss": 4.290764808654785,
      "val_accuracy": 0.175762939453125,
      "val_perplexity": 73.0222952319132,
      "learning_rate": 0.001,
      "model_name": "attention_mlp_512d_lr_1.00e-03",
      "training_time_minutes": 2.2242059270540873,
      "parameter_count": 69625088,
      "parameters_millions": 69.625088,
      "total_steps": 300,
      "best_val_loss": 4.698235034942627,
      "best_step": 270,
      "early_stopped": false,
      "final_train_loss": 4.901609897613525,
      "final_lr": 0.0009779754323328191
    },
    "lr_3.00e-03": {
      "val_loss": 2.3904561519622805,
      "val_accuracy": 0.451605224609375,
      "val_perplexity": 10.9184732903026,
      "learning_rate": 0.003,
      "model_name": "attention_mlp_512d_lr_3.00e-03",
      "training_time_minutes": 2.223625457286835,
      "parameter_count": 69625088,
      "parameters_millions": 69.625088,
      "total_steps": 300,
      "best_val_loss": 2.7914459705352783,
      "best_step": 270,
      "early_stopped": false,
      "final_train_loss": 2.934880256652832,
      "final_lr": 0.0029339262969984574
    }
  },
  "search_time_minutes": 9.1406289935112,
  "recommendation": "Use learning rate 3.00e-03 for long-term training"
}